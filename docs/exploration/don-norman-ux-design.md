# AirFit UX Design Analysis
*Through the lens of human-centered design*

**By Don Norman**
Date: December 18, 2025

---

## Executive Summary

AirFit represents an ambitious attempt to create an AI-native fitness coach with a "Bloom-inspired" design language emphasizing warmth and organic motion. The application demonstrates sophisticated technical implementation‚Äîactor-based concurrency, streaming AI responses, rich health data integration‚Äîbut reveals several fundamental tensions between its technical capabilities and human-centered design principles.

The core insight: **The app's technical sophistication has outpaced its conceptual model clarity.** Users are presented with powerful capabilities (AI coaching, body composition tracking, nutrition logging, workout analysis) without sufficient scaffolding to understand how these pieces fit together, when to use each, or what mental model should guide their interaction.

This analysis identifies where AirFit serves users well, where friction emerges from violations of fundamental HCI principles, and proposes 15 feature ideas grounded in cognitive psychology to bridge the gap between the system's power and human comprehension.

---

## Part I: Current UX Assessment

### Where AirFit Excels

**1. Progressive Onboarding Architecture**

The onboarding flow demonstrates understanding of progressive disclosure:
- **Splash ‚Üí Welcome ‚Üí Permissions ‚Üí Server Setup ‚Üí Conversational Interview**
- Each step has a clear affordance and single purpose
- Permission requests happen contextually, not as an overwhelming wall
- The conversational interview (`OnboardingInterviewView`) cleverly extracts profile data through natural dialogue rather than form fields

This is good Norman: the system reveals complexity gradually, matching the user's growing mental model.

**2. Strong Visual Feedback Systems**

The design system provides rich feedback:
- **Sensory feedback**: Haptic responses on tab changes, button presses
- **Animation vocabulary**: Organic springs (`bloom`, `bloomWater`) that feel responsive without being jittery
- **State visualization**: Loading states (shimmer text), thinking indicators (streaming wave), connection status badges

The `BreathingDot` and `StreamingWave` components effectively communicate "the AI is thinking" without text‚Äîvisual affordances that match user expectations.

**3. Adaptive Theming That Respects Context**

Time-of-day background tinting and light/dark mode support show environmental awareness:
- Morning: Cool blues
- Evening: Warm peaches
- Dark mode: Properly adjusted opacity and color values

This demonstrates understanding that interface design isn't static‚Äîcontext matters.

**4. Rich Data Visualization**

The Dashboard's body composition tracking (weight, body fat, lean mass, P-ratio) with interactive charts shows sophisticated data presentation:
- Touch-to-reveal detail
- LOESS smoothing to reduce noise
- Color-coded quality zones (P-ratio gauge)
- Tooltip explanations for complex metrics

The `InteractiveChartView` with scrubbing interaction is particularly well-executed.

**5. Accessibility Considerations**

Reduce motion support throughout:
```swift
@Environment(\.accessibilityReduceMotion) private var reduceMotion
if reduceMotion {
    Theme.background.ignoresSafeArea()
} else {
    EtherealBackground(currentTab: selectedTab)
}
```

This shows awareness that not all users benefit from animation.

---

### Where Friction Emerges: Design Violations

**1. Violation: Lack of System Visibility (Nielsen's Heuristic #1)**

**Problem**: The app has TWO AI providers (Claude/Gemini) with fundamentally different privacy models, but this critical distinction is buried in Settings.

```swift
@AppStorage("aiProvider") private var aiProvider = "claude"
```

A user in the Coach tab has no indication:
- Which AI they're talking to
- Whether their data is staying private or going to Google
- Why responses might feel different between providers

**Cognitive load**: Users must remember their choice from Settings. Working memory constraint violated‚Äîwe can only hold ~7 items. Privacy implications should be visible at point of use.

**Fix direction**: Provider indicator in ChatView header (subtle badge: "Private" vs "Cloud").

---

**2. Violation: Inconsistent Conceptual Model (Norman's Gulf of Evaluation)**

**Problem**: The app presents multiple overlapping views of the same data without clarifying relationships:
- Dashboard shows "This Week" nutrition averages
- Nutrition tab shows today's entries + 7-day ring
- Coach tab has health context pills (today's stats)
- Profile shows AI-learned patterns

**Gulf of Evaluation**: After logging food, which view updates? User doesn't know where to look for confirmation.

From `DashboardView.swift`:
```swift
if let ctx = weekContext {
    thisWeekCard(ctx)  // Server data
}
```

From `NutritionView.swift` (likely):
```swift
@Query private var entries: [NutritionEntry]  // Local SwiftData
```

**These are different sources!** Server aggregates vs local entries. No wonder users are confused about "source of truth."

**Fix direction**: Unified data flow narrative, explicit sync indicators, clear "last updated" timestamps.

---

**3. Violation: Poor Affordances for Critical Actions**

**Problem**: The "Done" button in onboarding interview appears/disappears based on AI-extracted profile completeness:

```swift
if profileProgress.isReadyToFinalize && !isLoading {
    Button(action: finalizeOnboarding) {
        Text("Done")
    }
    .transition(.scale.combined(with: .opacity))
}
```

**Affordance failure**: Button appears when `hasName && hasGoals` are true (extracted by LLM). But:
1. User doesn't know what triggers the button
2. No indication of "2 of 4 milestones complete"
3. Milestone completion is AI-determined (black box to user)

The `OnboardingMilestones` component shows progress, but mapping between conversation content and milestone completion is opaque.

**Fix direction**: Make extraction visible ("Got it - you're bulking"), show incomplete milestones as suggestions.

---

**4. Violation: Mode Errors (Norman's Design of Everyday Things, Chapter 4)**

**Problem**: ChatView has two invisible modes:
- Onboarding mode (shows banner, different personality)
- Normal coaching mode

```swift
@State private var isOnboarding = false
if isOnboarding {
    onboardingBanner  // "Getting to know you..."
}
```

Mode is server-determined (`profile.needsOnboarding`). User has no control, can't escape onboarding mode except by hitting "Done" button.

**Mode error risk**: User expects coaching ("How many calories today?") but gets onboarding questions ("What's your training split?").

**Fix direction**: Explicit mode indicator, escape hatch ("Skip to coaching"), clearer transition.

---

**5. Violation: Discoverability Failure (Norman's Signifiers)**

**Problem**: Many powerful features lack signifiers:
- Chart tooltips (info button is subtle, easy to miss)
- Editable profile items (tap to edit‚Äîno visual cue)
- Provider switching (Settings only, no nudge if server offline)
- QR code server setup (exists but users default to manual IP entry)

From `ProfileView.swift`:
```swift
Text(item)
    .contentShape(Rectangle())
    .onTapGesture {
        if onItemUpdated != nil {
            editText = item
            editingItem = item
        }
    }
```

**No signifier!** Plain text that happens to be tappable. Violates "perceived affordance" principle.

**Fix direction**: Subtle edit icon on hover/long-press, or permanent pencil icon.

---

**6. Violation: Errors Are Not Prevented (Nielsen's Heuristic #5)**

**Problem**: User can enter malformed nutrition data ("5 chicken" with no units), submit empty chat messages (prevented in code but affordance allows it), or delete profile data without undo.

From `SettingsView.swift`:
```swift
Button("Clear Everything", role: .destructive) {
    Task { await clearProfile() }
}
```

Confirmation dialog exists, but no preview of what will be lost, no undo, no export option first.

**Error prevention**: Should offer "Export profile first" before destructive action.

---

**7. Violation: Feedback Delays (Norman's Action-Perception Cycle)**

**Problem**: Many actions have delayed feedback:
- Nutrition logging ‚Üí Auto-sync happens in background ‚Üí Server reflects it "eventually"
- Health data ‚Üí HealthKit query ‚Üí Server sync ‚Üí Dashboard update
- Chat message ‚Üí Server ‚Üí AI ‚Üí Stream back

From `AutoSyncManager.swift`:
```swift
AutoSyncManager.shared.performLaunchSync(modelContext: modelContext)
```

Sync is invisible. User doesn't know if data is fresh or stale.

**Fix direction**: Explicit sync button with timestamp, progress indicator during sync.

---

## Part II: Cognitive Psychology Foundations

### The Mental Model Gap

**Current user mental model** (inferred from confused users):
- "I log food somewhere and the AI knows about it"
- "Charts show my progress somehow"
- "The coach gives me advice based on... something?"

**Actual system model**:
- SwiftData stores nutrition entries locally
- AutoSyncManager pushes to server periodically
- Server stores in `context_store.json` as daily snapshots
- AI receives context via `/chat` endpoint injection
- Charts pull from either HealthKit (body) or Server API (nutrition/workouts)
- Multiple AI providers with different privacy/capability tradeoffs

**Gap**: Massive. The system model is sophisticated (good engineering!) but the user-facing conceptual model is underspecified.

### Cognitive Load Analysis

**Working Memory Constraints**

Miller's Law: 7¬±2 items in working memory. Current ChatView header:
- Tab bar (5 tabs to remember)
- Current chat context (conversation history)
- Health context pills (4-6 metrics)
- Onboarding state (am I still onboarding?)
- Server connection status (sometimes visible)
- AI provider (invisible!)

**Overload.** User can't track all this context simultaneously.

**Recognition vs. Recall**

Good: Tab bar icons (recognition-based navigation)
Bad: Remembering which tab shows which time range (7-day vs today vs all-time)

### Visibility of System Status (Nielsen #1)

**Critical invisibilities**:
1. **Data freshness**: No "last synced" timestamp
2. **AI provider**: Claude vs Gemini hidden in Settings
3. **Onboarding progress**: Milestones shown but completion criteria opaque
4. **Server health**: Only visible when failed
5. **Background processes**: Auto-sync, insight generation, Hevy sync‚Äîall silent

---

## Part III: 15 Human-Centered Feature Ideas

### Category A: System Visibility & Feedback

**1. Unified Status Bar Component**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üü¢ Private Mode ‚Ä¢ Synced 2m ago    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Rationale**: Addresses visibility heuristic. Always-visible mini status bar (collapsible) showing:
- AI provider (icon + "Private"/"Cloud")
- Last sync timestamp
- Connection health

**Implementation**: New `SystemStatusBar` component, injected into all main views.

**Psychology**: Continuous feedback reduces uncertainty, builds trust. Users should never wonder "did that work?"

---

**2. Intelligent Empty States with Onboarding Nudges**

**Current**: Dashboard body section shows empty state: "No body data yet. Log your weight in Health app."

**Improved**:
```
üìä Body Composition Tracking

You haven't logged any weight data yet.

[Open Health App]  [Show Me How]

üí° Why track this?
Body composition trends reveal whether you're building muscle
or losing fat‚Äîway more useful than scale weight alone.
```

**Rationale**: Empty states are design opportunities. Transform "nothing to show" into "here's what you're missing and how to unlock it."

**Psychology**: Reduces gulf of execution (Norman). User doesn't just see empty space‚Äîthey see path forward.

---

**3. Action Confirmation with Undo**

**Current**: Delete profile item ‚Üí Gone immediately

**Improved**: Snackbar pattern
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ "Gain 15lbs muscle" removed  ‚îÇ
‚îÇ                    [UNDO]    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Rationale**: Prevent errors (Nielsen #5), reduce anxiety around destructive actions.

**Implementation**: 5-second undo window before permanent deletion. Toast notification pattern.

**Psychology**: Users explore more confidently when they know mistakes are reversible (exploratory learning).

---

**4. Progressive Disclosure in Chat Interface**

**Current**: Health context pills always visible (4-6 metrics)

**Improved**: Collapsible context panel
```
‚ñº Today's Context  [6 metrics]
  Steps: 8,432 ‚Ä¢ Calories: 280 ‚Ä¢ Sleep: 7.2hrs ...

(tap to expand full breakdown)
```

**Rationale**: Reduce cognitive load in primary task (chatting). Context available but not overwhelming.

**Psychology**: Fits working memory constraints. User focuses on conversation, references context when needed.

---

**5. Sync Awareness with Manual Trigger**

**Current**: Auto-sync in background, no visibility

**Improved**: Pull-to-refresh on all tabs + sync indicator
```
üîÑ Syncing nutrition data...
‚úì Synced 30 seconds ago

[Sync Now]
```

**Rationale**: Users want control over when data updates, especially before important views (pre-workout check).

**Implementation**: Pull-to-refresh gesture calls `AutoSyncManager.performLaunchSync()` + UI feedback.

**Psychology**: Sense of control reduces anxiety (locus of control theory).

---

### Category B: Conceptual Model Clarity

**6. Data Flow Visualization (Onboarding Step)**

**New onboarding screen** explaining system architecture:
```
üì± You log food here
    ‚Üì
‚òÅÔ∏è  Syncs to your server
    ‚Üì
ü§ñ AI coach reads context
    ‚Üì
üìä Charts show trends
```

**Rationale**: Build correct mental model from start. Users understand "local ‚Üí server ‚Üí AI" flow.

**Psychology**: Explicit instruction of conceptual model (scaffolding). Reduces confusion later.

---

**7. Provider Comparison & Recommendation**

**Current**: Settings shows Claude/Gemini bubbles, user picks

**Improved**: Decision support wizard
```
Which AI is right for you?

üîí Claude (Private)
‚úì Runs on your server
‚úì Conversations never leave your network
‚úó Requires server running

‚òÅÔ∏è Gemini (Cloud)
‚úì Works anywhere
‚úì Fast Google infrastructure
‚úó Data used to train AI models

Based on your setup: ‚ú® Claude Recommended
Your server is online and configured.
```

**Rationale**: Help users make informed choice matching their mental model ("I care about privacy" ‚Üí Claude).

**Psychology**: Decision fatigue reduction. System suggests default based on context.

---

**8. Contextual Help System (Tooltips++)**

**Current**: Some charts have info buttons ‚Üí modal sheet

**Improved**: Inline contextual help that teaches progressively
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ P-Ratio: 72 (Great)         ‚îÇ
‚îÇ                             ‚îÇ
‚îÇ ‚ÑπÔ∏è First time seeing this?   ‚îÇ
‚îÇ P-Ratio measures quality of ‚îÇ
‚îÇ weight changes. Tap to learn ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Rationale**: Discover-as-you-go learning. No separate help menu to hunt through.

**Psychology**: Just-in-time learning (Vygotsky's ZPD). Teach when user encounters concept, not before.

---

**9. Tab-Specific Tutorials (Coachmarks)**

**First time user opens Dashboard**:
```
üëÜ Tap any metric to expand weekly detail

üìä Charts are interactive - drag to scrub through time

‚ÑπÔ∏è Tap info icons to understand what each metric means
```

**Rationale**: Discoverability of hidden interactions (chart scrubbing, metric expansion).

**Implementation**: One-time overlay per tab, dismissible, never shown again.

**Psychology**: Teaches signifiers. Converts hidden affordances into perceived affordances.

---

**10. Smart Defaults Based on Usage Patterns**

**Current**: User must configure everything manually

**Improved**: System learns preferences
- If user always logs protein first ‚Üí suggest protein-rich foods in autocomplete
- If user checks dashboard at 6pm daily ‚Üí pre-sync data at 5:45pm
- If user asks nutrition questions in chat ‚Üí nudge toward Nutrition tab for detailed logging

**Rationale**: Reduce configuration burden. System adapts to user, not vice versa.

**Psychology**: Recognition memory (easier than recall). System remembers patterns user doesn't consciously track.

---

### Category C: Error Prevention & Recovery

**11. Validation with Suggestions**

**Current**: User enters "5 chicken" ‚Üí AI parses as best it can

**Improved**: Real-time validation
```
"5 chicken"
             ‚ö†Ô∏è Missing unit - did you mean:
             ‚Ä¢ 5 oz chicken breast
             ‚Ä¢ 5 pieces chicken tenders
             ‚Ä¢ 5 lbs whole chicken
```

**Rationale**: Prevent errors before they propagate to database/AI context.

**Implementation**: Pattern matching on nutrition input, suggest corrections.

**Psychology**: Error prevention > error recovery (Nielsen). Fix at source.

---

**12. Draft Mode for Chat Messages**

**Current**: Send button always enabled, sends immediately

**Improved**: Long-press send button ‚Üí "Save as draft" option

**Rationale**: Sometimes user is interrupted mid-message. Don't lose work.

**Psychology**: Respects user's work (perceived value of input). Reduces frustration.

---

**13. Onboarding Progress Persistence**

**Current**: If app crashes during onboarding, user starts over (actually, step is saved but unclear)

**Improved**: Clear resume indicator
```
Welcome back!

You were telling me about your training split.
Want to continue where we left off?

[Continue]  [Start Fresh]
```

**Rationale**: Respect user's time. Make persistence visible.

**Psychology**: Progress saved ‚Üí reduced anxiety about interruptions.

---

### Category D: Advanced Affordances

**14. Multi-Modal Input Options**

**Current**: Chat is text-only (Gemini supports photos but not wired up in UI)

**Improved**: Input toolbar
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Message...                         ‚îÇ
‚îÇ                                    ‚îÇ
‚îÇ üì∑  üé§  üìä  ‚Üë                      ‚îÇ
‚îÇ Photo Voice Data Send              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Rationale**: Match input mode to task. Photo of meal > typing ingredients.

**Psychology**: Natural mapping (Norman). Use modality that fits mental model (food is visual).

---

**15. Intelligent Notifications with Actionable Context**

**Current**: Generic "Log your food" reminders

**Improved**: Context-aware, actionable notifications
```
üçΩÔ∏è Dinner check-in

You're at 1,850 cal today (750 under target).

[Log Meal]  [I'm done eating]  [Snooze]

üí° Need 125g protein to hit goal - here are quick options:
‚Ä¢ Protein shake (40g)
‚Ä¢ Greek yogurt + granola (25g)
```

**Rationale**: Notifications should reduce friction, not add it. Make action easy from notification itself.

**Psychology**: Reduces steps to goal achievement (Fogg Behavior Model). Easier to do = more likely to do.

---

## Part IV: Norman's Signature Insights

### On Designing for Error

"The human mind is not designed to remember arbitrary things. It is designed to find meaning."

AirFit asks users to remember:
- Which tab shows which time range
- Whether they're in onboarding mode
- What their server IP is
- Which AI provider they chose

**Better**: Make the system remember. Show context at point of need.

### On Affordances vs. Signifiers

"Affordances define what actions are possible. Signifiers communicate where the action should take place."

AirFit has many affordances (tappable charts, editable profile items) but weak signifiers. Users don't know what's interactive.

**Better**: Add subtle visual cues. Not every button needs to be a raised 3D skeuomorph, but interactive elements need some distinction from static text.

### On Conceptual Models

"A good conceptual model allows us to predict the effects of our actions."

Can an AirFit user predict:
- What happens when they log food? (Goes to SwiftData ‚Üí syncs to server ‚Üí AI sees it in next chat)
- What happens when they switch AI providers? (Chat history persists? Personality changes?)
- What happens when they edit a profile item? (Server updates ‚Üí AI personality regenerates?)

Answers are opaque. System model exists (in code) but user-facing conceptual model is weak.

**Better**: Explicit "How this works" explanations at critical junctions.

### On the Importance of Feedback

"Feedback is the primary way we learn about the world."

AirFit provides feedback in some areas (animations, haptics) but fails in others:
- No feedback when auto-sync completes
- No feedback when AI extracts a milestone from conversation
- No feedback when background insight generation finishes

**Better**: Close the loop. Every user action should have perceptible consequence, even if it's "processing in background."

### On Human Memory

"Recognition is easier than recall. We are better at recognizing things we have seen before than remembering them."

Good: Tab bar icons (recognize "Coach" tab)
Bad: Remembering onboarding progress (what did the AI already extract?)

**Better**: Show what system knows. Profile view does this well ("What I've learned") but should be pervasive.

### On Simplicity

"The complexity of the system should be in the designer's head, not the user's."

AirFit's architecture is sophisticated:
- Actor-based concurrency
- Multi-provider AI routing
- Real-time health data sync
- Background task scheduling

Users shouldn't need to understand this. Yet the UI leaks implementation details (server configuration, sync timing, provider selection).

**Better**: Hide complexity by default, reveal only when user explicitly asks (Advanced settings, Debug mode).

---

## Conclusion: The Path Forward

AirFit is a **technically impressive** application with a **cognitively demanding** interface. The gap is not due to poor engineering‚Äîquite the opposite. The system is so capable that it overwhelms users with possibility.

The recommendations above share a common thread: **Make the invisible visible, the complex simple, and the opaque transparent.**

This doesn't mean dumbing down the app. It means applying the same thoughtfulness to the user's mental model that was applied to the codebase architecture.

**Three priorities**:

1. **System visibility**: Always show AI provider, sync status, data freshness
2. **Conceptual model**: Explain local ‚Üí server ‚Üí AI flow explicitly, once
3. **Discoverability**: Convert hidden affordances (tap to edit, chart scrubbing) into visible signifiers

The foundation is strong. The challenge now is making that strength comprehensible to the human on the other side of the screen.

---

**Don Norman**
December 18, 2025

*"Design is really an act of communication, which means having a deep understanding of the person with whom the designer is communicating."*
