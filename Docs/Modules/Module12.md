**Modular Sub-Document 12: Testing & Quality Assurance Framework**

**Version:** 1.0
**Parent Document:** AirFit App - Master Architecture Specification (v1.2)
**Prerequisites:**
    *   Completion of Modular Sub-Document 1: Core Project Setup & Configuration (which includes setting up XCTest targets).
    *   Ongoing completion of other feature modules (as tests will target code in those modules).
**Date:** May 24, 2025

**1. Module Overview**

*   **Purpose:** To establish a comprehensive testing strategy and framework for the AirFit application. This includes defining types of tests to be implemented, tools to be used, and guidelines for writing effective tests to ensure code quality, reliability, and catch regressions.
*   **Responsibilities:**
    *   Defining the overall testing strategy (unit, integration, UI tests).
    *   Setting up testing targets and configurations if not fully covered in Module 1.
    *   Establishing guidelines and best practices for writing tests.
    *   Implementing mock objects and a mocking strategy for external dependencies and services.
    *   Integrating code coverage tools and setting targets.
    *   Defining how AI Agents will be instructed to contribute to testing.
    *   (Human Role) Defining key user flows for manual QA and exploratory testing.
*   **Key Components within this Module:**
    *   XCTest targets (`AirFitTests`, `AirFitUITests`, `AirFitWatchAppTests`, `AirFitWatchAppUITests`).
    *   Mock object files (e.g., `MockAPIKeyManager.swift`, `MockCoachEngine.swift`, etc.) typically located in `Tests/Mocks/` or within respective test targets.
    *   Test plan files (`.xctestplan`) for organizing test execution.
    *   Code coverage reports (generated by Xcode).
    *   This document itself, serving as the testing strategy guide.

**2. Dependencies**

*   **Inputs:**
    *   AirFit App - Master Architecture Specification (v1.2) – for understanding component responsibilities and interactions.
    *   All other feature modules – as they provide the code to be tested.
*   **Outputs:**
    *   A robust suite of automated tests.
    *   A clear strategy for ongoing testing and QA.
    *   Increased confidence in code quality and application stability.

**3. Detailed Component Specifications & Agent Tasks**

---

**Task 12.0: Finalize Testing Target Configuration**
    *   **Agent Task 12.0.1:**
        *   Instruction: "Verify that XCTest targets (`AirFitTests`, `AirFitUITests` for iOS, and corresponding targets for WatchOS) are correctly configured in the Xcode project."
        *   Details: Ensure they can build and run. Check target memberships for any mock files.
        *   Acceptance Criteria: All test targets are properly set up and can execute empty test methods.

---

**Task 12.1: Establish Testing Guidelines and Best Practices**
    *   **Agent Task 12.1.1 (Human Task - Document Guidelines, Agent to be aware of them):**
        *   Instruction: "Create a `TESTING_GUIDELINES.md` file in the project root."
        *   Details: This document (created by you, the Vibe-Coder, with my help here) will outline:
            *   **Naming Conventions for Tests:** e.g., `test_FunctionName_Condition_ExpectedBehavior()` or `testGiven[Precondition]When[Action]Then[ExpectedResult]()`.
            *   **Arrange-Act-Assert (AAA) Pattern:** Tests should clearly separate setup, execution, and verification.
            *   **Test Independence:** Tests should not depend on each other or the order of execution.
            *   **Focus & Granularity:** Unit tests should test one small piece of logic.
            *   **Readability:** Tests should be easy to understand.
            *   **Mocking vs. Real Objects:** When to use mocks (for external dependencies, network calls, services not under test) vs. real instances (for internal logic).
            *   **Code Coverage:** Aim for a target percentage (e.g., 70-80% for critical business logic).
            *   **UI Test Stability:** Strategies for writing stable UI tests (e.g., using accessibility identifiers, avoiding reliance on timing).
        *   Acceptance Criteria: `TESTING_GUIDELINES.md` created with core principles. AI Agents will be instructed to follow these guidelines when generating tests.

---

**Task 12.2: Mocking Strategy & Implementation with DI**
    *   **Agent Task 12.2.1:**
        *   Instruction: "For each major service protocol defined in previous modules (e.g., `AIServiceProtocol`, `WhisperServiceWrapperProtocol`, `NotificationManagerProtocol`, `HealthKitManagerProtocol`, `APIKeyManagerProtocol`), create a corresponding mock implementation class in the relevant test target (e.g., `AirFitTests/Mocks/`)."
        *   **DI Integration:** All mocks should be registered in test containers using `DIBootstrapper.createTestContainer()` pattern.
        *   Details:
            *   Mock classes should conform to the protocol.
            *   Allow configuration of return values for methods (e.g., `mockAIAPIService.mockedResponse = .success(.textChunk("Test"))`).
            *   Track method calls and parameters (e.g., `mockAIAPIService.getStreamingResponseCalledWithRequest: AIRequest?`).
            *   Example (for `APIKeyManager` if it had a protocol `APIKeyManaging`):
                ```swift
                // In AirFitTests/Mocks/MockAPIKeyManager.swift
                // @testable import AirFit // If needed and mocks are in separate target

                class MockAPIKeyManager: APIKeyManaging { // Assuming protocol exists
                    var savedKeys: [AIProvider: String] = [:]
                    var getAPIKeyReturnValue: String? = nil
                    var saveAPIKeyCalledWith: (key: String, provider: AIProvider)?
                    var getAPIKeyCalledWithProvider: AIProvider?
                    // ... other tracking properties

                    func saveAPIKey(_ apiKey: String, forProvider provider: AIProvider) throws {
                        saveAPIKeyCalledWith = (apiKey, provider)
                        savedKeys[provider] = apiKey
                    }

                    func getAPIKey(forProvider provider: AIProvider) -> String? {
                        getAPIKeyCalledWithProvider = provider
                        return getAPIKeyReturnValue ?? savedKeys[provider]
                    }
                    // ... implement other protocol methods
                }
                ```        *   Acceptance Criteria: Mock implementations for key service protocols are created, allowing for controlled testing of components that depend on them. *(Vibe-Coder Note: You might need to instruct agents to first refactor existing services to use protocols if they don't already, to facilitate mocking via dependency injection).*

---

**Task 12.3: Unit Testing Implementation**
    *   **Agent Task 12.3.1 (General Instruction for AI Agents creating feature code):**
        *   Instruction (To be included with tasks for Modules 3-11): "When implementing any ViewModel, Manager, Engine, or Service class with non-trivial logic, you MUST also generate corresponding XCTest unit tests for its public methods. Place these tests in the `[ModuleName]Tests.swift` file within the `AirFitTests` target (or WatchOS equivalent). Follow `TESTING_GUIDELINES.md`."
    *   **Agent Task 12.3.2 (Specific Unit Test Generation - Example for `OnboardingViewModel` from Module 3):**
        *   Instruction: "Create `OnboardingViewModelTests.swift` in `AirFitTests/Modules/Onboarding/`. Write unit tests for `OnboardingViewModel` methods like `navigateToNextScreen`, `processCoreAspiration` (testing with a mock AI service), and `completeOnboarding` (testing data preparation and mock SwiftData saving)."
        *   Details for a test method:
            ```swift
            // In OnboardingViewModelTests.swift
            import XCTest
            @testable import AirFit // Allows access to internal types if needed
            import SwiftData

            @MainActor // If ViewModel interacts with @MainActor properties or UI-related tasks
            class OnboardingViewModelTests: XCTestCase {
                var viewModel: OnboardingViewModel!
                var mockModelContainer: ModelContainer! // For testing SwiftData interactions
                var mockContextAssembler: MockContextAssembler! // Assuming a mock
                var mockCoachEngine: MockCoachEngine! // Assuming a mock

                override func setUpWithError() throws {
                    try super.setUpWithError()
                    // Setup in-memory SwiftData store for testing
                    let config = ModelConfiguration(isStoredInMemoryOnly: true)
                    mockModelContainer = try ModelContainer(for: User.self, OnboardingProfile.self, /* other necessary models */ configurations: config)
                    
                    mockContextAssembler = MockContextAssembler() // Create your mocks
                    mockCoachEngine = MockCoachEngine()

                    // Initialize ViewModel with mock dependencies and modelContext from in-memory container
                    viewModel = OnboardingViewModel(
                        // Assuming OnboardingViewModel is updated to take these or a DI container
                        // modelContext: mockModelContainer.mainContext, // Or pass container
                        // contextAssembler: mockContextAssembler, 
                        // coachEngine: mockCoachEngine 
                        // For simplicity if VM only needs ModelContext for saving at the end:
                        // It might get it from environment or be passed it only in the completeOnboarding method.
                    )
                    // For now, let's assume the completeOnboarding method will take the context
                }

                override func tearDownWithError() throws {
                    viewModel = nil
                    mockModelContainer = nil
                    mockContextAssembler = nil
                    mockCoachEngine = nil
                    try super.tearDownWithError()
                }

                func testNavigateToNextScreen_FromOpening_GoesToLifeSnapshot() {
                    // Arrange
                    viewModel.currentScreen = .openingScreen

                    // Act
                    viewModel.navigateToNextScreen()

                    // Assert
                    XCTAssertEqual(viewModel.currentScreen, .lifeSnapshot, "Should navigate to Life Snapshot screen.")
                }

                func testCompleteOnboarding_SavesUserAndProfile() throws {
                    // Arrange
                    // Populate ViewModel with necessary onboarding data
                    viewModel.preferredUnits = "metric"
                    viewModel.coreAspirationText = "Test goal" 
                    // ... set other VM properties collected during onboarding ...
                    viewModel.achievementAcknowledgement = .enthusiasticCelebratory
                    viewModel.inactivityResponse = .gentleNudge


                    // Act
                    // The completeOnboarding method needs access to a ModelContext.
                    // If it's not injected at init, it must be passed as a parameter.
                    viewModel.completeOnboarding(modelContext: mockModelContainer.mainContext)


                    // Assert
                    // Fetch from the in-memory store to verify
                    let userDescriptor = FetchDescriptor<User>()
                    let users = try mockModelContainer.mainContext.fetch(userDescriptor)
                    XCTAssertEqual(users.count, 1, "A user should be created.")
                    XCTAssertEqual(users.first?.preferredUnits, "metric", "User preferred units should be saved.")

                    let profileDescriptor = FetchDescriptor<OnboardingProfile>()
                    let profiles = try mockModelContainer.mainContext.fetch(profileDescriptor)
                    XCTAssertEqual(profiles.count, 1, "An onboarding profile should be created.")
                    XCTAssertNotNil(profiles.first?.personaPromptData, "Persona prompt data should be generated.")
                    
                    // Example of decoding CommunicationPreferences (assuming it's in OnboardingProfile)
                    if let commPrefsData = profiles.first?.communicationPreferencesData {
                        let decoder = JSONDecoder()
                        let commPrefs = try decoder.decode(CommunicationPreferences.self, from: commPrefsData)
                        XCTAssertEqual(commPrefs.celebrationStyle, AchievementStyle.enthusiasticCelebratory.rawValue) // Ensure rawValues match
                    } else {
                        XCTFail("Communication Preferences data not found or not decodable.")
                    }
                }
                // Add more tests for other methods and edge cases
            }
            ```
        *   **Modern DI Testing Pattern:**
            ```swift
            // Using DIContainer for test setup
            @MainActor
            class OnboardingViewModelTestsWithDI: XCTestCase {
                var container: DIContainer!
                var factory: DIViewModelFactory!
                
                override func setUp() async throws {
                    try await super.setUp()
                    // Create test container with all mocks pre-registered
                    container = try await DIBootstrapper.createTestContainer()
                    factory = DIViewModelFactory(container: container)
                }
                
                func testOnboardingWithMockedServices() async throws {
                    // Arrange - Configure mocks
                    let mockAIService = try container.resolve(AIServiceProtocol.self) as! MockAIService
                    mockAIService.mockedResponse = .success(.text("Test response"))
                    
                    // Act - Create ViewModel via factory
                    let viewModel = try await factory.makeOnboardingViewModel()
                    await viewModel.processCoreAspiration()
                    
                    // Assert
                    XCTAssertEqual(viewModel.personaInsights?.count, 1)
                    XCTAssertTrue(mockAIService.generateResponseCalled)
                }
            }
            ```
        *   Acceptance Criteria: Unit tests for `OnboardingViewModel` are created, covering key logic paths and using mocks for external dependencies. Tests pass. Modern DI pattern is used for test isolation.

---

**Task 12.4: UI Testing Implementation (Basic)**
    *   **Agent Task 12.4.1 (General Instruction for AI Agents creating UI code):**
        *   Instruction (To be included with tasks for Modules 3, 6, 7, 8, 11): "When implementing significant UI views or user flows, you MUST also generate corresponding XCTest UI tests. Place these tests in the `[ModuleName]UITests.swift` file within the `AirFitUITests` target. Use accessibility identifiers for robust element querying. Follow `TESTING_GUIDELINES.md`."
    *   **Agent Task 12.4.2 (Specific UI Test Generation - Example for Onboarding Flow):**
        *   Instruction: "Create `OnboardingFlowUITests.swift` in `AirFitUITests/Modules/Onboarding/`. Write UI tests to verify navigation through the onboarding screens and basic interactions."
        *   Details:
            *   Ensure key UI elements in onboarding views have accessibility identifiers assigned (e.g., `view.accessibilityIdentifier = "onboarding.beginButton"`). This might require instructing the view-generating agent to add them.
            *   Use `XCUIApplication()` to launch the app.
            *   Interact with elements (tap buttons, enter text into `TextFields` if present).
            *   Assert existence of elements or changes in UI state.
            ```swift
            // In OnboardingFlowUITests.swift
            import XCTest

            class OnboardingFlowUITests: XCTestCase {
                var app: XCUIApplication!

                override func setUpWithError() throws {
                    try super.setUpWithError()
                    continueAfterFailure = false
                    app = XCUIApplication()
                    // Add launch arguments if needed (e.g., to signal UI tests are running, skip animations, use mock data)
                    // app.launchArguments += ["-UITesting"]
                    app.launch()
                }

                func testOpeningScreen_BeginButtonNavigates() throws {
                    // Arrange (App is launched)
                    // Ensure elements have accessibility identifiers set in the SwiftUI code
                    let beginButton = app.buttons["onboarding.beginButton"] // Example identifier

                    // Act
                    XCTAssertTrue(beginButton.waitForExistence(timeout: 5), "Begin button should exist")
                    beginButton.tap()

                    // Assert
                    // Check that an element unique to the next screen (e.g., LifeSnapshotView) appears
                    let lifeSnapshotTitle = app.staticTexts["lifeSnapshot.title"] // Example identifier
                    XCTAssertTrue(lifeSnapshotTitle.waitForExistence(timeout: 5), "Should navigate to Life Snapshot screen.")
                }
                // Add more UI tests for other parts of the flow
            }
            ```
        *   Acceptance Criteria: Basic UI tests for the onboarding flow are created and pass.

---

**Task 12.5: Code Coverage Configuration**
    *   **Agent Task 12.5.1:**
        *   Instruction: "Enable code coverage data collection in the active XCTest Test Plan (`.xctestplan`)."
        *   Details: Edit the test plan, go to the "Configurations" tab, and ensure "Code Coverage" is checked for the relevant targets.
        *   Acceptance Criteria: Code coverage is enabled in the test plan. When tests are run, Xcode shows coverage data.
    *   **Agent Task 12.5.2 (Human Task - Monitor Coverage):**
        *   Instruction: "Regularly review code coverage reports generated by Xcode after test runs. Identify areas of critical logic with low coverage and prioritize writing more unit tests for them."
        *   Acceptance Criteria: A process for monitoring and improving code coverage is in place.

---

**Task 12.6: Continuous Integration (CI) Considerations (Human Setup, Agent Awareness)**
    *   **Agent Task 12.6.1 (Human Task - Setup CI Pipeline):**
        *   Instruction: "Set up a Continuous Integration (CI) pipeline (e.g., using GitHub Actions, Xcode Cloud, Jenkins, Bitrise) that automatically builds the project and runs all unit and UI tests on every commit or pull request."
        *   Details: The CI pipeline should:
            *   Checkout the code.
            *   Select the correct Xcode version.
            *   Run `xcodebuild test -scheme AirFit -destination 'platform=iOS Simulator,name=iPhone 15 Pro' -enableCodeCoverage YES` (or similar command).
            *   Report test success/failure.
            *   (Optional) Upload code coverage reports.
            *   (Optional) Build and archive the app.
        *   Acceptance Criteria: A CI pipeline is configured and successfully runs tests automatically.
    *   **Agent Task 12.6.2 (AI Agent Awareness):**
        *   Instruction: "All generated code, including tests, must be compatible with execution in a CI environment. Avoid tests that rely on specific local machine configurations or interactive user input beyond what XCUITest simulates."
        *   Acceptance Criteria: AI agents are "aware" of CI requirements.

---

**Task 12.7: Final Review & Documentation Update**
    *   **Agent Task 12.7.1:**
        *   Instruction: "Review the `TESTING_GUIDELINES.md` and this sub-document (Module 12) for completeness and clarity."
        *   Acceptance Criteria: Documentation is up-to-date and provides a clear testing strategy.
    *   **Agent Task 12.7.2:**
        *   Instruction: "Commit any new test files, mock object files, and documentation changes related to the testing framework."
        *   Details: Commit message: "Feat: Establish Testing & QA Framework with guidelines and initial mocks".
        *   Acceptance Criteria: All framework-related changes are committed.

---

**4. Acceptance Criteria for Module Completion**

*   Testing guidelines (`TESTING_GUIDELINES.md`) are documented.
*   A strategy for mocking dependencies is established, and initial mock objects for key services are implemented.
*   AI agents are instructed to include unit tests with their feature code delivery. Example unit tests for a key ViewModel exist and pass.
*   AI agents are instructed to include basic UI tests for key user flows. Example UI tests for a key flow exist and pass.
*   Code coverage is enabled and a process for monitoring it is understood.
*   (Human-led) A CI pipeline is planned or set up to automate builds and tests.
*   The overall testing framework provides a solid foundation for ensuring app quality.

**5. Code Style Reminders for this Module (for tests)**

*   Test method names should be descriptive and follow conventions in `TESTING_GUIDELINES.md`.
*   Use the AAA pattern (Arrange, Act, Assert) clearly within each test.
*   Mocks should be used consistently for external dependencies to ensure unit tests are fast and reliable.
*   UI tests should use accessibility identifiers for element queries to improve stability.
*   All test code must pass SwiftLint checks.

---

This Testing & QA Framework module is about setting up the *process* and *infrastructure* for quality. The actual body of tests will grow as each feature module is developed and the AI agents contribute tests alongside their feature code. Your role, Vibe-Coder, will be to ensure agents *are* tasked with writing tests and to monitor the overall quality and coverage.
